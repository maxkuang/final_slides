{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>PhD Thesis Defense</center>\n",
    "## <center>Two Topics in Data Analysis: Sample-based Optimal Transport and Analysis of Turbulent Spectra from Ship Track Data</center>\n",
    "### <center>Simeng Max Kuang</center>\n",
    "#### <center>Courant Institute of Mathematical Sciences<br />New York University</center>\n",
    "#### <center>Committee Members:<br />Esteban G. Tabak, Oliver Bühler, Alfred Galichon, Aaditya V. Rangan, Carlos Fernandez-Granda</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Acknowledgements\n",
    "- A special thanks to my advisor: Esteban G. Tabak\n",
    "- Members in my thesis committee: Oliver Bühler, Alfred Galichon, Aaditya V. Rangan, Carlos Fernandez-Granda\n",
    "- My undergraduate advisor: Pingwen Zhang\n",
    "- Professors in CIMS who offer so many wonderful lectures and talks\n",
    "- All my friends and classmates during my five-year PhD\n",
    "- Many thanks to the support from my family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two Topics\n",
    "### Algorithms for optimal transport and barycenter problems\n",
    "### Analysis for turbulent spectra from ship track data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms for optimal transport and barycenter problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Analysis for turbulent spectra from ship track data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- Optimal transport and barycenter problems\n",
    "- Theoretical Perspective\n",
    "  - A Simpler Question\n",
    "  - Optimal Transport and Barycenter Algorithms\n",
    "  - Convergence Theorems\n",
    "- Sample-based Perspective\n",
    "  - Sample-based Optimal Transport Optimization\n",
    "  - Local Optimal Transport Problem\n",
    "  - Optimal Transport and Bayrcenter Algorithms\n",
    "  - Selection of Feature Functions\n",
    "- Numerical Results\n",
    "  - Optimal Transport and Barycenter Problems of Normal Distributions\n",
    "  - Applications: Shape Transform\n",
    "  - Applications: Color Transfer\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- __Optimal transport and barycenter problems__\n",
    "- Theoretical Perspective\n",
    "  - A Simpler Question\n",
    "  - Optimal Transport and Barycenter Algorithms\n",
    "  - Convergence Theorems\n",
    "- Sample-based Perspective\n",
    "  - Sample-based Optimal Transport Optimization\n",
    "  - Local Optimal Transport Problem\n",
    "  - Optimal Transport and Bayrcenter Algorithms\n",
    "  - Selection of Feature Functions\n",
    "- Numerical Results\n",
    "  - Optimal Transport and Barycenter Problems of Normal Distributions\n",
    "  - Applications: Shape Transform\n",
    "  - Applications: Color Transfer\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monge's Problem\n",
    "- The optimal transport problem, as proposed originally by Monge in 1781, addresses the displacement of a pile of soil between two locations with minimal cost. \n",
    "- Given the cost $c(\\mathbf{x},\\mathbf{y})$ of moving a unit mass from point $\\mathbf{x}$ to point $\\mathbf{y}$, one seeks the map $\\mathbf{y} = \\mathbf{f}(\\mathbf{x})$ that minimizes total cost. Suppose the two piles of soil are two probability measures $\\mu_1$ and $\\mu_2$, \n",
    "$$\\inf_{\\mathbf{f}_\\sharp\\mu_1 = \\mu_2} \\int_{\\mathbb{R}^d} c(\\mathbf{x}, \\mathbf{f}(\\mathbf{x})) d\\mu(\\mathbf{x}),$$\n",
    "where $\\mathbf{f}_\\sharp\\mu_1$ represents the pushforward measure.\n",
    "![Monge](fig-Monge.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kantorovich's Formulation\n",
    "- Kantorovich relaxed Monge's problem, allowing the movement of soil from one to multiple locations and vice versa.\n",
    "- Denoting the mass transported from $\\mathbf{x}$ to $\\mathbf{y}$ by $\\pi(\\mathbf{x},\\mathbf{y})$,  the minimization problem can be rewritten as\n",
    "$$\\inf_{\\pi\\in\\Pi_{\\mu_1,\\mu_2}} \\int c(\\mathbf{x},\\mathbf{y})\\pi(\\mathbf{x},\\mathbf{y})d\\mathbf{x} d\\mathbf{y},$$\n",
    "where $\\Pi_{\\mu_1,\\mu_2}$ is the set of all the transfer plans $\\pi(\\mathbf{x},\\mathbf{y})$ satisfying the marginal constraints\n",
    " $$\\int\\pi(\\mathbf{x},\\mathbf{y})d\\mathbf{y} = \\mu_1(\\mathbf{x}),$$\n",
    " $$\\int\\pi(\\mathbf{x},\\mathbf{y})d\\mathbf{x} = \\mu_2(\\mathbf{y}).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kantorovich's Dual Theorem\n",
    "$$ \\inf_{\\pi\\in\\Pi_{\\mu_1,\\mu_2}} \\int c(\\mathbf{x},\\mathbf{y})\\pi(\\mathbf{x},\\mathbf{y})d\\mathbf{x} d\\mathbf{y}=\\sup_{\\phi(\\mathbf{x}) + \\psi(\\mathbf{y}) \\leq c(\\mathbf{x},\\mathbf{y})} \\int\\phi(\\mathbf{x})d\\mu_1(\\mathbf{x}) + \\int\\psi(\\mathbf{y})d\\mu_2(\\mathbf{y}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- With minor conditions, one can prove the solution of Kantorovich's formulation is __unique__ and equals to the solution of Monge's problem.\n",
    "- For instance $c(\\mathbf{x},\\mathbf{y}) = \\|\\mathbf{x} - \\mathbf{y}\\|^2$ in $\\mathbb{R}^d$, $\\mu$ absolutely continuous with respect to Lebesgue. (*Gangbo and McCann 1996*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monge-Ampere PDE\n",
    "- The optimal map from $\\mu$ to $\\nu$ is in the form of gradients:\n",
    "$$\\mathbf{y} = \\nabla\\phi(\\mathbf{x})$$\n",
    "where $\\phi$ is the function in the dual problem, and must be __convex__ in $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The optimal $\\phi$ satisfies the __Monge-Ampere PDE__:\n",
    "\n",
    "$$  \\det{(\\nabla^2\\phi(\\mathbf{x}))} d\\mu_2(\\nabla\\phi(\\mathbf{x})) = d\\mu_1(\\mathbf{x}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In an integral form\n",
    "\n",
    "$$  \\int_{\\mathbb{R}^d} h(\\nabla\\phi(\\mathbf{x})) d\\mu_1(\\mathbf{x}) = \\int_{\\mathbb{R}^d} h(\\mathbf{y})d\\mu_2(\\mathbf{y})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wasserstein Distance and Wasserstein Barycenter\n",
    "- For $c(\\mathbf{x},\\mathbf{y}) = \\|\\mathbf{x} - \\mathbf{y}\\|^2$ in $\\mathbb{R}^d$, the transportation cost induces the 2-Wasserstein distance:\n",
    "$$  W_2(\\mu_1, \\mu_2) = \\left(\\min_{\\pi\\in\\Pi_{\\mu_1,\\mu_2}}\\int_{\\mathbb{R}^d} \\|\\mathbf{x}-\\mathbf{y}\\|^2d\\pi(\\mathbf{x},\\mathbf{y})\\right)^{\\frac{1}{2}},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is a metric of the space of measures (Villani 2008):\n",
    "\n",
    "$$ P_2(\\mathbb{R}^d) := \\left\\lbrace \\mu\\in P(\\mathbb{R}^d); \\quad \\int_{\\mathbb{R}^d} \\|\\mathbf{x}\\|^2 d\\mu(\\mathbf{x})<+\\infty\\right\\rbrace .$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wasserstein Barycenter Measure\n",
    "- Center of measures. $\\mu_1, \\mu_2, \\cdots, \\mu_K$ and weights $w_1, w_2,\\cdots, w_K$.\n",
    "\n",
    "$$ \\bar{\\nu} = \\underset{\\nu\\in P_2(\\mathbb{R}^d)}{\\mathrm{argmin}} \\sum_{k=1}^K w_k W^2_2(\\mu_k, \\nu).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A natural extention to barycenter of points:\n",
    "\n",
    "$$ \\bar{\\mathbf{x}} = \\sum_{k=1}^K w_k\\mathbf{x}_k = \\underset{\\mathbf{x}}{\\mathrm{argmin}} \\sum_{k=1}^K w_k \\|\\mathbf{x} - \\mathbf{x}_k\\|^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- More natural than the simple average\n",
    "![c](barycenterMeasure.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Applications\n",
    "  * Economics: matching models, quantile methods, ...:  see *Galichon (2016)*\n",
    "  * Image Processing: EMD distance, image segmentation, color transfer, ...: Rubner et al. (1998), Pitie et al. (2007)\n",
    "  * Medical Research: Cancer network: Ni et al. (2009)\n",
    "  * Machine Learning: Arjovsky et al.(2017)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms\n",
    "- Benamou and Brenier (2000) introduced a computational fluid approach\n",
    "- Oberman and Ruan (2015) fast liner programming algorithm\n",
    "- Solomon et al. (2015) entropy regularization\n",
    "- Tabak and Trigila (2014) data-driven algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- Optimal transport and barycenter problems\n",
    "- __Theoretical Perspective__\n",
    "  - __A Simpler Question__\n",
    "  - __Optimal Transport and Barycenter Algorithms__\n",
    "  - __Convergence Theorems__\n",
    "- Sample-based Perspective\n",
    "  - Sample-based Optimal Transport Optimization\n",
    "  - Local Optimal Transport Problem\n",
    "  - Optimal Transport and Bayrcenter Algorithms\n",
    "  - Selection of Feature Functions\n",
    "- Numerical Results\n",
    "  - Optimal Transport and Barycenter Problems of Normal Distributions\n",
    "  - Applications: Shape Transform\n",
    "  - Applications: Color Transfer\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Theoretical Perspective: Goals\n",
    "- Theoretical algorithms and motivations;\n",
    "- A characterization of the barycenter measure;\n",
    "- General convergence theorem for iterative algorithms of measures;\n",
    "- Proof of convergence for proposed algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Simpler Question\n",
    "- Assuming that we already have a __black box solver__ for the optimal transport problem, find an efficient algorithm that uses it to solve the barycenter problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Wasserstein barycenter problem:\n",
    "\n",
    "$$\\bar{\\nu} = \\underset{\\nu\\in P_2(\\mathbb{R}^d)}{\\mathrm{argmin}} \\sum_{k=1}^K w_k W^2_2(\\mu_k, \\nu)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Start from some initial measure $\\nu = \\nu_0$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Approach $\\bar{\\nu}$ through an iterative procedure:\n",
    "\n",
    "$$\\nu_{n} \\xrightarrow{\\hspace{0em}?} \\nu_{n+1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simpler Question: Illustration\n",
    "![123](illustration11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simpler Question: Illustration\n",
    "![123](illustration12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simpler Question: Illustration\n",
    "- Suppose $\\mathbf{s}_k(\\mathbf{y})$ is the optimal map from $\\nu$ to $\\mu_k$. The total cost can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{k=1}^K w_k\\int \\|\\mathbf{y} -\\mathbf{s}_k(\\mathbf{y})\\|^2 d\\nu(\\mathbf{y})\n",
    "= \\int\\left[\\sum_{k=1}^K w_k\\|\\mathbf{y} - \\mathbf{s}_k(\\mathbf{y})\\|^2\\right]d\\nu(\\mathbf{y}).\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We move $\\mathbf{y}\\rightarrow \\mathbf{f}(\\mathbf{y})$, such that\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{k=1}^K w_k\\|\\mathbf{y} - \\mathbf{s}_k(\\mathbf{y})\\|^2 \\geq \\sum_{k=1}^K w_k\\|\\mathbf{f}(\\mathbf{y}) - \\mathbf{s}_k(\\mathbf{y})\\|^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Candidate for $\\mathbf{f}(\\mathbf{y})$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{f}(\\mathbf{y}) = \\sum_{k=1}^K w_k\\mathbf{s}_k(\\mathbf{y})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simpler Question: Illustration\n",
    "![123](illustration13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simpler Question: Illustration\n",
    "![123](illustration14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simpler Question: <br>Basic Barycenter Algorithm\n",
    "1. Set $\\nu = \\nu_0$ where $\\nu_0\\in P_2(\\mathbb{R}^d)$ is an arbitrary initial measure;\n",
    "2. Find the optimal maps $\\mathbf{s}_k$ from $\\nu$ to $\\mu_k$ ($k = 1, 2,\\cdots, K$);\n",
    "3. Define $\\mathbf{f}(\\mathbf{y}) = \\sum_{k=1}^K w_k\\mathbf{s}_k(\\mathbf{y})$;\n",
    "4. Set $\\nu = \\mathbf{f}_\\sharp \\nu$ and return to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simpler Question: <br>Basic Barycenter Algorithm\n",
    "- The algorithm reduces the total transportation cost at every step;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The algorithm __stops__ only when:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{y} = \\sum_{k=1}^K w_k\\mathbf{s}_k(\\mathbf{y});\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This means, barycenter measure $\\bar{\\nu}$ must satisfy the above equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithms: McCann Interpolant and Barycenter\n",
    "- A special 2-barycenter problem\n",
    "\n",
    "\\begin{equation}\n",
    " \\min_{\\nu\\in P_2(\\mathbb{R}^d)} \\frac{1}{2}W_2^2(\\mu_1, \\nu) + \\frac{1}{2}W_2^2(\\mu_2, \\nu),\n",
    "\\end{equation}\n",
    "- Its solution coincides with the McCann interpolant measure.\n",
    "\n",
    "$$\\mathbf{y} = \\frac{1}{2}\\mathbf{s}_1(\\mathbf{y}) + \\frac{1}{2}\\mathbf{s}_2(\\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The optimal map from $\\mu_1$ to $\\mu_2$ is given by\n",
    "\n",
    "$$ \\mathbf{z} = \\mathbf{s}_2(\\mathbf{s}^{-1}_1(\\mathbf{x}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- With more segments on the McCann Interpolants\n",
    "\n",
    "\\begin{equation}\n",
    " \\min_{\\substack{\\nu_0,\\nu_1,\\cdots,\\nu_K\\in P_2(\\mathbb{R}^d)\\\\ \\nu_0 = \\mu_1,\\nu_K = \\mu_2}} \\sum_{k=1}^K w_kW_2^2(\\nu_k,\\nu_{k-1}) .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Define $\\mathbf{s}_k$ as the optimal from $\\nu_{k-1}$ to $\\nu_k$, and \n",
    "\n",
    "$$\\lambda_k = \\sum_{i=1}^k \\frac{1}{w_i}\\left/ \\sum_{i=1}^K \\frac{1}{w_i}\\right.$$\n",
    "$$  \\mathbf{s}^c = \\mathbf{s}_K\\circ\\mathbf{s}_{K-1}\\circ\\cdots\\circ\\mathbf{s}_1.$$\n",
    "- $\\mathbf{s}^c$ should be the optimal map from $\\mu_1$ to $\\mu_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms: Illustration\n",
    "![123](illustration21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms: Theoretical Optimal Transport Algorithm (TOT)\n",
    "1. Let $\\nu_0 = \\mu_1$ and $\\nu_K = \\mu_2$. Set $\\nu_k$ ($k=1,2,\\cdots, K-1$) to arbitrary initial measures in $P_2(\\mathbb{R}^d)$; \n",
    "2. Find the optimal maps $\\mathbf{s}_k$ from $\\nu_{k-1}$ to $\\nu_k$ ($k = 1, 2,\\cdots, K$);\n",
    "3. Define $\\mathbf{s}^c$ and the weights $\\lambda_k$;\n",
    "4. For $k=1,2,\\cdots, K-1$, update $\\nu_k$ to \n",
    "$$\n",
    "\\nu_k = [\\lambda_k\\mathbf{s}^c + (1 - \\lambda_k) \\mathbf{id}]_{\\sharp} \\mu_1\n",
    "$$\n",
    "and return to step 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms: Illustration\n",
    "![123](illustration22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms: Composite Theoretical Barycenter Algorithm (CTB)\n",
    "\n",
    "1. Set $\\nu = \\nu_0$ where $\\nu_0\\in P_2(\\mathbb{R}^d)$ is an arbitrary initial measure;\n",
    "2. Run steps 1,2,3 of the TOT algorithm\n",
    "once to find a map $\\mathbf{s}_k^c$ from $\\nu$ to $\\mu_k$ for each $k=1,2,\\cdots,K$;\n",
    "3. Define the map $\\mathbf{f}^c$ as:\n",
    "$$\\mathbf{f}^c(\\mathbf{y}) = \\sum_{k=1}^K w_k \\mathbf{s}_k^c(\\mathbf{y});$$\n",
    "4. Update $\\nu$ and $\\mathbf{s}_k^c$:\n",
    " $$\\nu = \\mathbf{f}^c_\\sharp\\nu;$$\n",
    " $$\\mathbf{s}_k^c = \\mathbf{s}_k^c\\circ(\\mathbf{f}^c)^{-1};$$\n",
    "5. Run step 4, 2, 3 of TOT once for each pair $(\\nu, \\mu_k)$ to update $\\mathbf{s}_k^c$ and return to step 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Algorithms: Remarks\n",
    "- __General__ optimal transport and barycenter problems can be solved assuming we can solve __local__ optimal transport problems;\n",
    "- TOT and CTB problems only works in the theoretical setting.\n",
    "- Convergence? More general?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence Theorems: Challenges\n",
    "- What converges: measures? map functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Map or Transfer Plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Convergences of probability Measures: weak convergence? $W_2$ convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Convergence of barycenter measure: convergence of (multidimensional) transfer plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence Theorems: <br>A Property of the Barycenter Measure\n",
    "\n",
    "- __Theorem 1(Agueh and Carlier 2011)__. Consider the barycenter problem with measures $\\mu_1,\\mu_2,\\cdots,\\mu_K \\in P_2(\\mathbb{R}^d)$ and positive normalized weights $w_1, w_2,\\cdots, w_K$. If one of the measure is absolute continuous, a measure $\\nu$ is the barycenter if and only if for almost all $\\mathbf{y}\\in\\mathrm{supp}(\\nu)$,\n",
    " $$\\mathbf{y}= \\sum_{k=1}^K w_k\\mathbf{s}_k(\\mathbf{y}),$$\n",
    "where $\\mathbf{s}_k$ is the optimal map from $\\nu$ to $\\mu_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sketch of Proof\n",
    "- If $\\nu$ is the barycenter (Necessity):\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\displaystyle   \\sum_{k=1}^K w_k W^2_2(\\nu,\\mu_k)&\\geq \\displaystyle\\int\\left[\\sum_{k=1}^K w_k\\|\\mathbf{f}(\\mathbf{y}) - \\mathbf{s}_k(\\mathbf{y})\\|^2\\right]d\\nu(\\mathbf{y})\\\\\n",
    "  &\\displaystyle=\\int\\left[\\sum_{k=1}^K w_k\\|\\tilde{\\mathbf{y}} - \\mathbf{s}_k(\\mathbf{f}^{-1}(\\tilde{\\mathbf{y}}))\\|^2\\right]d\\mathbf{f}_\\sharp\\nu(\\tilde{\\mathbf{y}})\\\\\n",
    "  &\\displaystyle\\geq \\sum_{k=1}^K w_k W^2_2(\\mathbf{f}_\\sharp\\nu,\\mu_k).\n",
    "\\end{array}\n",
    "$$\n",
    "- You must have $\\mathbf{y} = \\mathbf{f}(\\mathbf{y})$ almost everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sketch of Proof\n",
    "- When $\\mathbf{y}= \\sum_{k=1}^K w_k\\mathbf{s}_k(\\mathbf{y})$: (Sufficiency)\n",
    "$$\\mathbf{y} = \\sum_{k=1}^K w_k \\mathbf{}s_k(\\mathbf{\\mathbf{y}}) = \\sum_{k=1}^K w_k \\nabla \\left[\\frac{\\|\\mathbf{y}\\|^2}{2} - \\frac{\\psi^*_k(\\mathbf{y})}{w_k}\\right] = \\mathbf{y} - \\nabla\\sum_{k=1}^K \\psi^*_k(\\mathbf{y}).$$\n",
    "This shows $\\sum_{k=1}^K \\psi^*_k(\\mathbf{y})$ is a constant, from the dual formulation of the multidimensional optimal transport problem, we know that such $\\psi_k$ achieves the maximum (minimum), thus $\\nu$ has to be the barycenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence Theorems: <br>A Property of the McCann Interpolant\n",
    "- __Theorem 2__. Consider measures $\\nu_0,\\nu_1,\\cdots,\\nu_K$ and positive normalized weights $w_1, w_2,\\cdots, w_K$. Suppose $\\mathbf{s}_k$ is the optimal map from $\\nu_{k-1}$ to $\\nu_{k}$. Measures $(\\nu_0,\\nu_1,\\cdots,\\nu_K)$ minimize \n",
    "$$\n",
    "\\begin{equation}\n",
    " \\min_{\\substack{\\nu_0,\\nu_1,\\cdots,\\nu_K\\in P_2(\\mathbb{R}^d)\\\\ \\nu_0 = \\mu_1,\\nu_K = \\mu_2}} \\sum_{k=1}^K w_kW_2^2(\\nu_k,\\nu_{k-1}) .\n",
    "\\end{equation}\n",
    "$$\n",
    "if and only if for almost all $\\mathbf{y}\\in\\mathrm{supp}(\\mu_1)$ and all $k = 1, 2,\\cdots,K$,\n",
    "$$\n",
    "\\begin{equation}\n",
    " \\mathbf{s}_k\\circ\\cdots\\circ\\mathbf{s}_2\\circ\\mathbf{s}_1(\\mathbf{}y) = (1 - \\lambda_k)\\mathbf{y} + \\lambda_k\\mathbf{s}^c(\\mathbf{y}).\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence Theorems: $L$-descending Map\n",
    "- __Definition ($L$-descending Map)__ .Suppose $\\mathcal{F}$ is a map between measures:\n",
    "$$\n",
    " \\begin{equation}\n",
    " \\mathcal{F}:P_2(\\mathbb{R}^d)\\rightarrow P_2(\\mathbb{R}^d)\n",
    "\\end{equation}\n",
    "$$ and $L:P_2(\\mathbb{R}^d)\\rightarrow \\mathbb{R}$ is a cost function with a lower bound. We call $\\mathbf{f}$ a __$L$-descending map__ if it satisfies the following conditions:\n",
    "  1. $\\mathcal{F}$ is a continuous map with respect to the $W_2$ metric on $P_2(\\mathbb{R}^d)$.\n",
    "  2. For arbitrary $\\pi\\in P_2(\\mathbb{R}^d)$, we have\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "   L(\\mathcal{F}\\pi) \\leq L(\\pi)\n",
    "  \\end{equation}\n",
    "  $$\n",
    "  and equality holds if and only if\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "   \\mathcal{F}\\pi = \\pi = \\pi^*\n",
    "  \\end{equation}\n",
    "  $$\n",
    "  where $\\pi^*$ is a minimizer of $L$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence Theorems: $L$-descending Map\n",
    "- __Theorem 3__ .Let $\\mathcal{F}$ be an $L$-descending map. We define a sequence $\\{\\pi^n\\}_{n = 1, 2,...}$ through $$\\pi^{n+1} = \\mathcal{F}\\pi^n,\\quad n = 0,1,...$$ where $\\pi^0 \\in P_2(\\mathbb{R}^d)$ is an arbitrary initial measure. If the following two conditions are satisfied:\n",
    "  1. $\\{\\pi^n\\}_{n = 1, 2,...}$ is sequentially compact with respect to the $W_2$ metric,\n",
    "  2. $L$ is continuous with respect to the $W_2$ metric and it has a unique minimizer $\\pi^*$, then $$\\pi^n\\xrightarrow[]{W_2} \\pi^*$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence Theorems: <br>General Descending Optimal Transport Algorithm\n",
    "- __Definition (GDOT)__. Consider an iterative algorithm that updates a transfer plan $\\pi\\in\\Pi_{\\mu_1,\\mu_2}$: \n",
    "$$\n",
    "\\begin{equation}\n",
    " \\pi^{n+1} = \\mathcal{F}\\pi^n,\\quad n = 0,1,\\cdots\n",
    "\\end{equation}\n",
    "$$\n",
    "We call an algorithm a general descending optimal transport algorithm if the associated iteration map $\\mathcal{F}$ is a $L$-descending map in which the cost function $L(\\pi)$ is the total transport cost for optimal transport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- __Theorem 4__. Suppose the two target measures $\\mu_1$ and $\\mu_2$ are in $P_2(\\mathbb{R}^d)$ and the optimal transfer plan is unique. Then the GDOT algorithm converges to the optimal transfer plan $\\pi^*$ in the $W_2$ metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence Theorems: <br>General Descending Barycenter Algorithm\n",
    "- __Definition (GDB)__. Given an arbitrary $L$-descending map $\\mathcal{F}$ for the GDOT algorithms, we define the map:\n",
    " $$\n",
    " \\begin{equation}\n",
    " \\mathcal{G}:\\Pi_{\\mu_1,\\cdots,\\mu_2,\\cdots,\\mu_K}\\rightarrow \\Pi_{\\mu_1,\\cdots,\\mu_2,\\cdots,\\mu_K}\n",
    " \\end{equation}\n",
    " $$\n",
    " and use it to update the current multimarginal measure $\\hat{\\pi}^n$:\n",
    " $$\n",
    " \\begin{equation}\n",
    " \\hat{\\pi}^{n+1} = \\mathcal{G}\\hat{\\pi}^{n}.\n",
    " \\end{equation}\n",
    " $$\n",
    " We call such an algorithm a general descending barycenter algorithm if $\\mathcal{G}$ is induced by $\\mathcal{F}$ through the following steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence Theorems: <br>General Descending Barycenter Algorithm\n",
    "1. Derive $\\nu^n$ from $\\hat{\\pi}^n$:\n",
    "  $$\n",
    "  \\nu(E) := \\hat{\\pi}\\left( \\{(\\mathbf{x}_1,\\cdots,\\mathbf{x}_K)| \\sum_{k=1}^K w_k\\mathbf{x}_k \\in E\\}\\right),\\text{ for all Borel sets } E.\n",
    "  $$\n",
    "2. For $k = 1,2,\\cdots, K$, set the current transfer plan $\\pi_k^n$ to\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "  \\pi_k^n(E_\\nu\\times E_{k}) := \\nu(E_\\nu)\\cdot\\hat{\\pi}^n\\left( \\{(\\mathbf{x}_1,\\cdots,\\mathbf{x}_K)| \\mathbf{x}_k \\in E_{k}\\}\\right), \\text{ for all Borel sets } E_\\nu, E_{k};\n",
    "  \\end{equation}\n",
    "  $$\n",
    "3. Apply the map $\\mathcal{F}$ to all $\\pi_k^n$,\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "  \\pi_k^{n+1} = \\mathcal{F}\\pi_k^n\n",
    "  \\end{equation}\n",
    "  $$ and define the conditional measure $\\pi_k^{n+1}|\\mathbf{y}$;\n",
    "4. Set $\\hat{\\pi}^{n+1}$ as the product measure:\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "  \\hat{\\pi}^{n+1}(E_1\\times E_2\\times\\cdots\\times E_K) = \\int_{\\mathbb{R}^d} \\left[\\prod_{k=1}^K\\pi_k^{n+1}| \\mathbf{y}(E_k)\\right]d\\nu(\\mathbf{y}).\n",
    "  \\end{equation}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- __Theorem 5__. The general descending barycenter algorithm has the following properties:\n",
    "  1. $\\mathcal{G}$ is a $L$-descending map, where the cost function $L$ is the barycenter cost in the multimarginal formulation:\n",
    " $$\n",
    "\\begin{equation}\n",
    " L(\\hat{\\pi}) = \\int_{\\mathbb{R}^{dK}}\\left(\\sum_{k=1}^Kw_k\\|\\mathbf{x}_k - \\bar{\\mathbf{x}}\\|^2\\right)d\\hat{\\pi}(\\mathbf{x}_1,\\cdots,\\mathbf{x}_K), \\quad \\hat{\\pi}\\in\\Pi_{\\mu_1,\\mu_2,\\cdots,\\mu_K};\n",
    "\\end{equation}\n",
    "$$\n",
    "  2. Suppose the barycenter problem has a unique solution, the GDB algorithm always converges to the minimizer $\\hat{\\pi}^*$ in $W_2$; the corresponding $\\nu^*$ is the barycenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence Theorem: Illustration\n",
    "![1](illustration3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theoretical Perspective: Conclusions\n",
    "- Three algorithms are proposed:  \n",
    "  __Basic Theoretical Barycenter Algorithm (BTB)__  \n",
    "  __Theoretical Optimal Transport Algorithm (TOT)__  \n",
    "  __Composite THeoretical Barycenter Algorithm (CTB)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- General convergence theorems for a wide range of algorithms;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- __General__ optimal transport and barycenter problems can be solved if we can solve __local__ optimal transport problems;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Theoretical algorithms are not directly applicable to practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- Optimal transport and barycenter problems\n",
    "- Theoretical Perspective\n",
    "  - A Simpler Question\n",
    "  - Optimal Transport and Barycenter Algorithms\n",
    "  - Convergence Theorems\n",
    "- __Sample-based Perspective__\n",
    "  - __Sample-based Optimal Transport Optimization__\n",
    "  - __Local Optimal Transport Problem__\n",
    "  - __Optimal Transport and Bayrcenter Algorithms__\n",
    "  - __Selection of Feature Functions__\n",
    "- Numerical Results\n",
    "  - Optimal Transport and Barycenter Problems of Normal Distributions\n",
    "  - Applications: Shape Transform\n",
    "  - Applications: Color Transfer\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Sample-based Perspective: Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample-based Optimal Transport\n",
    "- Only sample sets are available, data distributions are unknown: i.i.d. $\\{\\mathbf{x}_i\\}_{i=1}^{N_x}$ and $\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$.\n",
    "- We would like to define and find the __optimal map__ from $\\{\\mathbf{x}_i\\}_{i=1}^{N_x}$ to $\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- An existing framework:\n",
    "![](illustration4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Sample-based Optimal Transport\n",
    "- Discrete form 1: $\\mu_1$ and $\\mu_2$ are modeled simply using dirac measures of data points.\n",
    "- Discrete form 2: $\\mu_1$ and $\\mu_2$ are derived using density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- because if we think the unknown distribution is a continuous measure, the solution should be a map.\n",
    "- In many data applications, a map gives a more definite answer than a transfer plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sample-based Optimal Transport: <br>Two Elements of Optimal Map\n",
    "- We define the optimal map __directly__ from data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A map $\\mathbf{f}$ pushes measure $\\mu_1$ to $\\mu_2$:\n",
    "\n",
    "$$\\begin{equation}\\mathbf{f}_\\sharp\\mu_1 = \\mu_2\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\mathbf{f}$ minimizes the transport cost, is a gradiant of a convex function $\\phi$:    \n",
    "\n",
    "$$ \\begin{equation}\\min_{\\mathbf{f}} \\int \\|\\mathbf{x} - \\mathbf{f}(\\mathbf{x})\\|^2 d\\mu_1(\\mathbf{x}),\\quad \\mathbf{f}(\\mathbf{x}) = \\nabla\\phi(\\mathbf{x})\\end{equation}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sample-based Optimal Transport: <br>Sample-based Equivalence\n",
    "- When we only have samples, we need to define:\n",
    "\n",
    "$$ \\{\\nabla\\phi(\\mathbf{x}_i)\\}_{i=1}^{N_x}=\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- __Definition (sample-based equivalence)__. We say that a sample set $\\{\\mathbf{x}_i\\}_{i=1}^{N_x}$ is sample-based equivalent to $\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$ with respect to a set of feature functions $\\{F_j(\\mathbf{x})\\}_{j=1}^{M}:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ if\n",
    "$$ \\frac{1}{N_x}\\sum_{i=1}^{N_x}F_j(\\mathbf{x}_i) = \\frac{1}{N_y}\\sum_{j=1}^{N_y}F_j(\\mathbf{y}_i),\\quad j=1,2,\\cdots, {M}$$ We denote this equivalence relation by\n",
    "$$\\{\\mathbf{x}_i\\}_{i=1}^{N_x}\\sim\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The optimal map $\\nabla\\phi$ is constrained by\n",
    "\n",
    "$$ \\{\\nabla\\phi(\\mathbf{x}_i)\\}_{i=1}^{N_x}\\sim\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sample-based Optimal Transport: $\\nabla\\phi$\n",
    "- Approximate the integral over measure by sample means:\n",
    "\n",
    "$$\\min_\\phi\\frac{1}{N_x}\\sum_{i=1}^{N_x} \\|\\nabla\\phi(\\mathbf{x}_i) - \\mathbf{x}_i\\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Extra constraints needs to be added on $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We put $\\phi$ in the space of all feature functions:\n",
    "$$  \\phi(\\mathbf{x}) = \\frac{\\|\\mathbf{x}\\|^2}{2} + \\sum_{j=1}^{M} s_jF_j(\\mathbf{x})$$\n",
    "- The $\\frac{\\|\\mathbf{x}\\|^2}{2}$ term is included so that when all the $s_j$ are zeros $\\phi(\\mathbf{x})$ corresponds to the identity map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sample-based Optimal Transport: <br>Comparison with Classical Optimal Transport\n",
    "- Correspondence:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(\\nabla\\phi)_\\sharp \\mu_1 = \\mu_2&\\quad\\rightarrow&\\{\\nabla\\phi(\\mathbf{x}_i)\\}_{i=1}^{N_x}\\sim\\{\\mathbf{y}_i\\}_{i=1}^{N_y}\\\\\n",
    " \\int \\| \\nabla\\phi(\\mathbf{x})-\\mathbf{x}\\|^2 d\\mu_1(\\mathbf{x})&\\quad\\rightarrow& \\frac{1}{N_x}\\sum_{i=1}^{N_x} \\|\\nabla\\phi(\\mathbf{x}_i) - \\mathbf{x}_i\\|^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another correspondence: Monge-Ampere PDE,\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\int_{\\mathbb{R}^d} h(\\nabla\\phi(\\mathbf{x})) d\\mu_1(\\mathbf{x}) = \\int_{\\mathbb{R}^d} h(\\mathbf{y})d\\mu_2(\\mathbf{y})&\\quad\\rightarrow&\n",
    " \\frac{1}{N_x}\\sum_{i=1}^{N_x}F_j(\\nabla\\phi(\\mathbf{x}_i)) = \\frac{1}{N_y}\\sum_{j=1}^{N_y}F_j(\\mathbf{y}_i)\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Feature functions are test functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sample-based Optimal Transport\n",
    "- With input data $\\{\\mathbf{x}_i\\}_{i=1}^{N_x}$ and $\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$, and a set of $C^1$ feature functions $\\{F_j:\\mathbb{R}^d\\rightarrow\\mathbb{R}\\}_{j=1}^M$. The solution of the following constrained optimization problem of $s_1, s_2,\\cdots, s_M$ defines the optimal map.\n",
    "$$\n",
    "\\begin{equation}\n",
    " \\min_{\\{\\nabla\\phi(\\mathbf{x}_i)\\}_{i=1}^{N_x}\\sim\\{\\mathbf{y}_i\\}_{i=1}^{N_y}}\\sum_{i=1}^{N_x} \\|\\nabla\\phi(\\mathbf{x}_i) - \\mathbf{x}_i\\|^2,\n",
    "\\end{equation}\n",
    " $$ where $$\\phi(\\mathbf{x}) = \\frac{\\|\\mathbf{x}\\|^2}{2} + \\sum_{j=1}^{M} s_jF_j(\\mathbf{x})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Local Optimal Transport Problem: Observation\n",
    " - $$\\frac{1}{N_x}\\sum_{i=1}^{N_x}F_j\\left(\\mathbf{x}_i + \\sum_{j=1}^M s_j\\nabla F_j(\\mathbf{x}_i)\\right) = \\frac{1}{N_y}\\sum_{i=1}^{N_y}F_j(\\mathbf{y}_i),\\quad j=1,\\cdots,M$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- From the sample-base equivalence relation, we have $M$ unknowns and $M$ equations;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For general feature functions $F$, the system is nonlinear in $s_1,\\cdots,s_M$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- no solution? multiple solution? global optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Local Optimal Transport Problem\n",
    "- When the two datasets are close, everything is good!\n",
    "- Denote \n",
    "\n",
    "$$\\mathbf{s} = (s_1,s_2,\\cdots,s_M),\\quad\\mathbf{F}(\\mathbf{x}) = (F_1(\\mathbf{x}),F_2(\\mathbf{x}),\\cdots,F_M(\\mathbf{x}))^T,$$\n",
    "$$ \\mathbf{a} = \\frac{1}{N_x}\\sum_{i=1}^{N_x}\\mathbf{F}(\\mathbf{x}_i),\\quad \\mathbf{b} = \\frac{1}{N_y}\\sum_{i=1}^{N_y}\\mathbf{F}(\\mathbf{y}_i).$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- __Theorem (local optimal transport)__. There exsits $\\varepsilon$, when $\\|\\mathbf{a} - \\mathbf{b}\\|_{\\infty} < \\varepsilon$, we have\n",
    "  1. The sample-based equivalence relation has a unique solution $\\mathbf{s} = \\mathbf{s}^*$ near $\\mathbf{0}$;\n",
    "  2. The corresponding $\\phi^*$ function defined by $\\mathbf{s}^*$ achives the __global minimum__ of the sample-based optimal transport problem;\n",
    "  3. If in addition all the feature functions are $C^2$ and their Hessian matrices are uniformly bounded, $\\phi^*$ is __convex__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Local Optimal Transport Problem: Remarks\n",
    "- We can define\n",
    "$$\\mathbf{F}(\\mathbf{x}) = (F_1(\\mathbf{x}),F_2(\\mathbf{x}),\\cdots,F_M(\\mathbf{x}))^T,$$\n",
    "$$ \\mathbf{G}(\\mathbf{s}) = \\frac{1}{N_x}\\sum_{i=1}^{N_x}\\mathbf{F}(\\mathbf{x}_i + \\mathbf{s}^T\\nabla\\mathbf{F}(\\mathbf{x}_i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- The sample-based equivalence writes:\n",
    "$$\\mathbf{G}(\\mathbf{s}) = \\mathbf{b}$$\n",
    "- We know $\\mathbf{G}(\\mathbf{0}) = \\mathbf{a}$. Thus when $\\mathbf{a}$ and $\\mathbf{b}$ are close, inverse function theorem can help proving the existence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Local Optimal Transport Problem: Remarks\n",
    "- Local sample-based optimal transport problem has great properties,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is an existence theorem, but the size of $\\varepsilon$ can be estimated,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One can solve a __local sample-based optimal transport problem__ by solving the sample-based equivalence relation, a $M$ equation system, using standard nonlinear system solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can naturally combine the __theoretical algorithms__ with the __local optimal transport solver__. We will be able to derive solutions for __general sample-based optimal transport and barycenter problem__!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms:<br>Sample-based Optimal Transport Algorithm (SOT)\n",
    "\n",
    "1. Let $\\{\\mathbf{x}_i^0\\}_{i=1}^{N_x} = \\{\\mathbf{x}_i\\}_{i=1}^{N_x}$ and $\\{\\mathbf{x}_i^K\\}_{i=1}^{N_y} = \\{\\mathbf{y}_i\\}_{i=1}^{N_y}$. Set initial sample sets $\\{\\mathbf{x}_i^k\\}_{i=1}^{N_x}$ ($k=1,2,\\cdots, K-1$); \n",
    "2. Select a set of feature functions $\\{F_j(\\mathbf{x})\\}_{j=1}^M$;\n",
    "3. Set the current set $\\{\\mathbf{z}_i\\}_{i=1}^{N_x}=\\{\\mathbf{x}_i^0\\}_{i=1}^{N_x}$;\n",
    "4. For $k=1,2,\\cdots, K$, solve the __local sample-based optimal map__ $\\mathbf{f}$ from $\\{\\mathbf{z}_i\\}_{i=1}^{N_x}$ to $\\{\\mathbf{x}_i^k\\}_{i=1}^{N_x}$ using a standard nonlinear system solver and update $\\{\\mathbf{z}_i\\}_{i=1}^{N_x}$ through\n",
    "$$\\begin{equation}\n",
    " \\{\\mathbf{z}_i\\}_{i=1}^{N_x} = \\{\\mathbf{f}(\\mathbf{z}_i)\\}_{i=1}^{N_x};\n",
    "\\end{equation}$$\n",
    "5. For $k=1,2,\\cdots, K-1$, update $\\{\\mathbf{x}_i^k\\}_{i=1}^{N_x}$ through\n",
    " $$\\begin{equation}\n",
    "  \\{\\mathbf{x}_i^k\\}_{i=1}^{N_x} = \\{\\frac{K - k}{K}\\mathbf{x}_i^0 + \\frac{k}{K}\\mathbf{z}_i\\}_{i=1}^{N_x}\n",
    " \\end{equation}$$and go to step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "<font size=\"30\"> $\\{\\mathbf{f}_1(\\mathbf{z}_i)\\}\\quad\\quad\\{\\mathbf{f}_2(\\mathbf{f}_1(\\mathbf{z}_i))\\}\\quad\\quad\\{\\mathbf{f}_3(\\mathbf{f}_2(\\mathbf{f}_1(\\mathbf{z}_i)))\\}\\quad\\quad\\{\\mathbf{x}^3_i\\}$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration51.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration52.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration54.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration55.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration56.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration57.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration58.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Illustration\n",
    "![](illustration51.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms:<br>Composite Sample-based Barycenter Algorithm (CSB)\n",
    "\n",
    "1. Set the initial sample set $\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$;\n",
    "2. Select a set of feature functions $\\{F_j(\\mathbf{x})\\}_{j=1}^M$;\n",
    "3. Run step 1,3,4 of __SOT__ once for each pair $(\\{\\mathbf{y}_i\\}_{i=1}^{N_y},\\{\\mathbf{x}_i^k\\}_{i=1}^{N_k})$ to map $\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$ to a new set $\\{\\mathbf{z}_i^k\\}_{i=1}^{N_y}$;\n",
    "4. Update $\\{\\mathbf{y}_i\\}_{i=1}^{N_y}$ through\n",
    "$$\\begin{equation}\n",
    " \\{\\mathbf{y}_i\\}_{i=1}^{N_y} = \\left\\{\\sum_{k=1}^K w_k\\mathbf{z}_i^k\\right\\}_{i=1}^{N_y}.\n",
    "\\end{equation}$$\n",
    "5. Run step 5, 3, 4 of SOT once for each pair $(\\{\\mathbf{y}_i\\}_{i=1}^{N_y},\\{\\mathbf{x}_i^k\\}_{i=1}^{N_k})$ to update $\\{\\mathbf{z}_i^k\\}_{i=1}^{N_y}$ and go to step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Transport and Bayrcenter Algorithms: Algorithm Parameters\n",
    "- Stop parameter $\\varepsilon$ and stop criterion: \n",
    "$$\\frac{1}{N_x}\\sum_{i=1}^{N_x}\\|\\mathbf{z}_i^{\\text{before}} - \\mathbf{z}_i^{\\text{after}}\\|^2 <\\varepsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Number of segments $M$, should be big enough so that each subproblem is local. In practice $M = 10\\sim 50$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Feature functions;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selection of Feature Functions\n",
    "- The optimal map lives in the space of gradients of feature functions. The more feature functions one uses, the richer the structure of the optimal map;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Computational cost highly depends on feature functions: $M$ and computation of feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Feature functions can be defined by the user, based on expert knowledge of the nature of the sample sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Selection of Feature Functions: Moments\n",
    "- Choosing for feature functions the components of $x$:\n",
    "\n",
    "$$\\begin{equation}\n",
    " F_j(\\mathbf{x}) = \\mathbf{x}^{(j)},\\quad j = 1,2,\\cdots, d.\n",
    "\\end{equation}$$\n",
    "- The solution of sample-based optimal transport problem is a simple translation and matches the sample mean of two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Choosing for feature functions the first and second moments, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  F_j(\\mathbf{x}) &= \\mathbf{x}^{(j)},\\quad j = 1,2,\\cdots, d,\\\\\n",
    "  F_{\\frac{(2n-i+1)i}{2} +j}(\\mathbf{x})& = \\mathbf{x}^{(i)}\\mathbf{x}^{(j)},\\quad 1\\leq i\\leq j\\leq d.\n",
    "\\end{align}\n",
    "$$ \n",
    "- The sample-based optimal map is a linear map that matches the means and covariance matrices:\n",
    "\n",
    "$$\\nabla\\phi(\\mathbf{x}) = \\mathbf{Ax}+\\mathbf{b}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It gives the true solutions to optimal transport and barycenter problems of normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The corresponding basic barycenter algorithm gives a fixed-point iteration algorithm for barycenter problem of normal distributions (Agueh and Carlier 2011 and Alvarez-Esteban et al. 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Selection of Feature Functions: Kernel Functions\n",
    "-  For a given location $\\mathbf{z}_0$ and a bandwidth parameter $h$, we can define a kernel function $F(\\mathbf{x})$ such that\n",
    "$$\n",
    "\\begin{equation}\n",
    " F(\\mathbf{x}) = K\\left(\\frac{\\mathbf{x}-\\mathbf{z}_0}{h}\\right)\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Corresponding sample feature mean is:\n",
    "$$\\begin{equation}\n",
    " \\frac{1}{N_x}\\sum_{i=1}^{N_x}K\\left(\\frac{\\mathbf{x}_i-\\mathbf{z}_0}{h}\\right),\n",
    "\\end{equation}$$\n",
    "  which can be interpreted as the value of a kernel density estimator at point $\\mathbf{z}_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- One natural candidate for the kernel function $K(\\mathbf{x})$ is the Gaussian kernel\n",
    "  $$\n",
    "\\begin{equation}\n",
    " K_h(\\mathbf{x}) = \\frac{1}{\\sqrt{(2\\pi h)^d}}\\exp{\\left(-\\frac{\\|\\mathbf{x}\\|^2}{2h^2}\\right)},\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Selection of Feature Functions: Kernel Functions\n",
    "- Selection of a set of $\\{(\\mathbf{z}_j, h_j)\\}_{j=1}^M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - $\\mathbf{z}_j$ as grid points in the sample space;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Data-driven approaches: i.e. mean shift algorithm (Cheng 1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Selection of Feature Functions: Other Techniques\n",
    "- PCA, Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Nerual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Prior Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample-based Perspective: Conclusions\n",
    "- Two algorithms are proposed:  \n",
    "  __Sample-based Optimal Transport Algorithm (SOT)__  \n",
    "  __Composite Sample-based Barycenter Algorithm (CSB)__  \n",
    "  Algorithms are set to be applied to optimal transport and barycenter problems with sample sets as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sample-based algorithms are extended from theoretical algorithm by combining with local optimal transport solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sample sets are compared through feature functions. Different sample-based solutions can be derived from different feature functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- Optimal transport and barycenter problems\n",
    "- Theoretical Perspective\n",
    "  - A Simpler Question\n",
    "  - Optimal Transport and Barycenter Algorithms\n",
    "  - Convergence Theorems\n",
    "- Sample-based Perspective\n",
    "  - Sample-based Optimal Transport Optimization\n",
    "  - Local Optimal Transport Problem\n",
    "  - Optimal Transport and Bayrcenter Algorithms\n",
    "  - Selection of Feature Functions\n",
    "- __Numerical Results__\n",
    "  - __Optimal Transport and Barycenter Problems of Normal Distributions__\n",
    "  - __Applications: Shape Transform__\n",
    "  - __Applications: Color Transfer__\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical Results: Normal Distributions\n",
    "- Optimal Transport of normal distributions has closed-form solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For multidimensional normal distributions $\\mathcal{N}(\\mathbf{m}_1,\\mathbf{\\Sigma}_1)$ and $\\mathcal{N}(\\mathbf{m}_2,\\mathbf{\\Sigma}_2)$, the optimal map will be a linear map. We have\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{y} = \\mathbf{m}_2 + (\\mathbf{x}-\\mathbf{m}_1) \\mathbf{\\Sigma}_1^{-1/2}(\\mathbf{\\Sigma}_1^{1/2}\\mathbf{\\Sigma}_2\\mathbf{\\Sigma}_1^{1/2})^{1/2}\\mathbf{\\Sigma}_1^{-1/2}.\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It can be solved from the sample-based equivalence relation with first and second moments feature functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numerical Results: Normal Distributions\n",
    "- Numerical Experiments Setting:\n",
    "    1. Draw sample sets from two fixed 2D normal distributions, sample size $N_x = N_y = 200$.\n",
    "    2. Feature functions are choosen to be __first and seconde moments__.\n",
    "    3. Number of segments $K = 12$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "cd Dropbox/2016r/thesis/slides\n",
    "jupyter nbconvert thesis_defense_slides.ipynb --to slides --post serve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|![alt](normalSet.png) | ![alt](normalError.png)|\n",
    "|:---:|:---:|\n",
    "| Sample Sets | Error |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numerical Results: Normal Distributions\n",
    "<center><img src=\"normalOT.gif\" alt=\"Drawing\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numerical Results: Normal Distributions\n",
    "- The barycenter problem of normal distributions satisfies the following equation:\n",
    "$$ \\mathbf{m}_y = \\sum_{k=1}^K w_k \\mathbf{m}_k,$$\n",
    "$$ \\mathbf{\\Sigma}_y = \\sum_{k=1}^K w_k(\\mathbf{\\Sigma}_y^{1/2}\\mathbf{\\Sigma}_k\\mathbf{\\Sigma}_y^{1/2})^{1/2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Basic barycenter algorithm using OT solutions is a simple fixed-point algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- CSB algorithm works on general sample-based barycenter problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numerical Results: Normal Distributions\n",
    "|![alt](barycenterNormalSet.png) | ![alt](barycenterNormalError.png)|\n",
    "|:---:|:---:|\n",
    "| Sample Sets | Error |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numerical Results: Normal Distributions\n",
    "<center><img src=\"baryNorm.gif\" alt=\"Drawing\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numerical Results: <br>Normal Distributions to Gaussian Mixture Models\n",
    "|![alt](mixture3.gif) | ![alt](mixture4.gif) |![alt](mixture7.gif) | ![alt](mixture15.gif)|\n",
    "|:---:                |:---:                 |:---:                |:---:                 |\n",
    "|a                |b               |c               |d               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications: Shape Transform\n",
    "- The task is to find maps or barycenters for different shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Optimal Transport provides a good metric to between arbitrary shapes. Choosing $L_2$ cost, the __sample-based__ algortihms gives:\n",
    "    1. Optimal map\n",
    "    2. All the intermediate shapes\n",
    "    3. One to one correspondence of arbitrary points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Challenges: Sharp boundary, Different topology, Shape representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shape Transform: Technical Details\n",
    "- For a bounded region (shape) $\\Omega\\in\\mathbb{R}^d$, we define a grid in $\\mathbb{R}^d$ and choose grid points $\\{\\mathbf{x}_i\\}$ in $\\Omega$ to represent the shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- From an arbitray sample set $\\{\\mathbf{x}_i\\}$, we first derive a density estimator $\\tilde{p}$ and define the shape to be regions with $\\tilde{p}(\\mathbf{x}) > \\varepsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Algorithm parameters\n",
    "    1. Feature functions are choosen to be gaussian kernels on a $7\\times 7$ grid with bandwidth $h = 0.5, 1$. ($49$ feature functions).\n",
    "    2. $K = 20$, $\\epsilon = 10^{-4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shape Transform: Ellipse to Ring\n",
    "|![alt](ringmoon2_0-1.png) | ![alt](ringmoon2_1-1.png) |![alt](ringmoon2_2-1.png) |![alt](ringmoon2_4-1.png) |![alt](ringmoon2_4-1.png) |\n",
    "|:---:                |:---:                 |:---:                |:---:                |:---:                |\n",
    "|![alt](ringmoon_0-1.png) | ![alt](ringmoon_1-1.png) |![alt](ringmoon_2-1.png) |![alt](ringmoon_3-1.png) |![alt](ringmoon_4-1.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shape Transform: More Examples\n",
    "|![alt](dbmoon.gif) | ![alt](starmoon.gif) |![alt](ringbird.gif) |\n",
    "|:---:                |:---:                 |:---:                |\n",
    "|half moon to half moon|star to ball|bird to ring|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications: Color Transfer\n",
    "- Modify the color of a __source image__ according to the color palette of a __target image__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Computer vision applications: \n",
    "    1. Recolor images collected in bad lighting, bad climatic condition.\n",
    "    2. Movie industry: adjusting images to approporite color mood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Optimal transport and related methods has been developed in many articles (Reinhart et al. 2001, Welsh et al. 2002, Faridul et al. 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Transfer: Parrot Example\n",
    "|![](parrot_1.jpg)|![](parrot_2.jpg)|![](post_processing_parrot.jpg)|\n",
    "|:---: |:---: |:---: |\n",
    "|Source image|Target image|Output image|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from numpy import genfromtxt\n",
    "parrot_1 = genfromtxt('parrot_data_1_slides.csv', delimiter=',')\n",
    "parrot_2 = genfromtxt('parrot_data_2_slides.csv', delimiter=',')\n",
    "parrot_maped = genfromtxt('parrot_data_maped_slides.csv', delimiter=',')\n",
    "\n",
    "x1 = parrot_1[:,0]\n",
    "y1 = parrot_1[:,1]\n",
    "z1 = parrot_1[:,2]\n",
    "parrot_source = go.Scatter3d(\n",
    "    x=x1,\n",
    "    y=y1,\n",
    "    z=z1,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='rgb(51,51,179)',\n",
    "        size=1,\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name = 'source image'\n",
    ")\n",
    "\n",
    "x2 = parrot_2[:,0]\n",
    "y2 = parrot_2[:,1]\n",
    "z2 = parrot_2[:,2]\n",
    "parrot_target = go.Scatter3d(\n",
    "    x=x2,\n",
    "    y=y2,\n",
    "    z=z2,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='red',\n",
    "        size=1,\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name = 'target image'\n",
    ")\n",
    "\n",
    "x3 = parrot_maped[:,0]\n",
    "y3 = parrot_maped[:,1]\n",
    "z3 = parrot_maped[:,2]\n",
    "parrot_maped_f = go.Scatter3d(\n",
    "    x=x3,\n",
    "    y=y3,\n",
    "    z=z3,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='rgb(51,51,179)',\n",
    "        size=1,\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name = 'maped image'\n",
    ")\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig1 = tools.make_subplots(rows=1, cols=2, specs=[[{'is_3d': True}, {'is_3d': True}]])\n",
    "fig1.append_trace(parrot_source, 1, 1)\n",
    "fig1.append_trace(parrot_target, 1, 2)\n",
    "fig1.layout = layout\n",
    "iplot(fig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "init_notebook_mode()\n",
    "x, y, z = np.random.multivariate_normal(np.array([0,0,0]), np.eye(3), 200).transpose()\n",
    "trace1 = go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        line=dict(\n",
    "            color='rgba(217, 217, 217, 0.14)',\n",
    "            width=0.5\n",
    "        ),\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "x2, y2, z2 = np.random.multivariate_normal(np.array([0,0,0]), np.eye(3), 200).transpose()\n",
    "trace2 = go.Scatter3d(\n",
    "    x=x2,\n",
    "    y=y2,\n",
    "    z=z2,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='rgb(127, 127, 127)',\n",
    "        size=12,\n",
    "        symbol='circle',\n",
    "        line=dict(\n",
    "            color='rgb(204, 204, 204)',\n",
    "            width=1\n",
    "        ),\n",
    "        opacity=0.9\n",
    "    )\n",
    ")\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='simple-3d-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Transfer: The Meta-algorithm\n",
    "- To do good color transfer, optimal transport is not enough. We adopt Rabin et al (2015)'s meta-algorithm:\n",
    "- Spatio-color Clustering: cluster the image into subsets, which builds a smaller sample set\n",
    "- Sample-based optimal transport algorithm\n",
    "- Image synthethesis: recover color of each pixel from cluster sample sets\n",
    "- Post-processing: restore sharp details of the original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|![](parrot_1.jpg)|![](superpixel_parrot_1.jpg)|![](map_syn_parrot.jpg)|![](post_processing_parrot.jpg)|\n",
    "|:---: |:---: |:---: |:---: |\n",
    "|Source image|Spatio-color Clustering|Image synthesis|Post-processing|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Transfer: Technique Details\n",
    "- Spatio-color clustering: super-pixel method, 2000 clusters, CIELAB space\n",
    "- Sample-based optimal transport: SOT, $K = 20, 5\\times 5\\times 5$ grid Gaussian kernels, $h = 1$\n",
    "- Image synthesis: Special expectation-maximization algorithm\n",
    "- Post-processing: iterative TMR filters (Rabin et al. 2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Transfer: Parrot Example\n",
    "|![](post_processing_parrot.jpg)|![](2007_parrot.jpg)|![](2011_parrot.jpg)|![](2014_parrot.jpg)|\n",
    "|:---: |:---: |:---: |:---: |\n",
    "|Sample-based optimal transport|Raw optimal transport Pitie et al.(2007)|Variational model Papadakis et al. (2011)|Relaxed Optimal Transport Rabin et al.(2014)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x2 = parrot_2[:,0]\n",
    "y2 = parrot_2[:,1]\n",
    "z2 = parrot_2[:,2]\n",
    "parrot_target1 = go.Scatter3d(\n",
    "    x=x2,\n",
    "    y=y2,\n",
    "    z=z2,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='red',\n",
    "        size=1,\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name = 'target image'\n",
    ")\n",
    "\n",
    "x3 = parrot_maped[:,0]\n",
    "y3 = parrot_maped[:,1]\n",
    "z3 = parrot_maped[:,2]\n",
    "parrot_maped1 = go.Scatter3d(\n",
    "    x=x3,\n",
    "    y=y3,\n",
    "    z=z3,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='rgb(51,51,179)',\n",
    "        size=1,\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name = 'maped image'\n",
    ")\n",
    "data = [parrot_maped1, parrot_target1]\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig2 = go.Figure(data=data, layout=layout)\n",
    "iplot(fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\n",
    "    '<script>'\n",
    "        'var waitForPlotly = setInterval( function() {'\n",
    "            'if( typeof(window.Plotly) !== \"undefined\" ){'\n",
    "                'MathJax.Hub.Config({displayAlign: \"center\" });'\n",
    "                'clearInterval(waitForPlotly);'\n",
    "            '}}, 250 );'\n",
    "    '</script>'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Transfer: More Examples\n",
    "|![](castle_1.jpg)|![](castle_2.jpg)|![](post_processing_castle.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|Source image|Target image|Output image|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Transfer: More Examples\n",
    "|![](flower_1.jpg)|![](flower_2.jpg)|![](post_processing_flower.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|Source image|Target image|Output image|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Transfer: More Examples\n",
    "|![](night_1.jpg)|![](night_2.jpg)|![](post_processing_night.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|Source image|Target image|Output image|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- Optimal transport and barycenter problems\n",
    "- Theoretical Perspective\n",
    "  - A Simpler Question\n",
    "  - Optimal Transport and Barycenter Algorithms\n",
    "  - Convergence Theorems\n",
    "- Sample-based Perspective\n",
    "  - Sample-based Optimal Transport Optimization\n",
    "  - Local Optimal Transport Problem\n",
    "  - Optimal Transport and Bayrcenter Algorithms\n",
    "  - Selection of Feature Functions\n",
    "- Numerical Results\n",
    "  - Optimal Transport and Barycenter Problems of Normal Distributions\n",
    "  - Applications: Shape Transform\n",
    "  - Applications: Color Transfer\n",
    "- __Summary__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline: A Preconditioning Procedure For Optimal Transport\n",
    "  - The Basic Framework: Admissible Map Pairs\n",
    "  - Examples of Admissible Map Pairs\n",
    "  - The Optimal Linear Pair\n",
    "  - General Cost Functions\n",
    "  - Preconditioning Procedure\n",
    "  - Numerical Tests\n",
    "  - Summary\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Thank you!</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
